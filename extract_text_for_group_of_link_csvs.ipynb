{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import wget\n",
    "import newspaper\n",
    "from newspaper import Article\n",
    "import json\n",
    "import pandas as pd\n",
    "pd.set_option(\"max_colwidth\", 600)\n",
    "import ast\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import requests\n",
    "import time\n",
    "import numpy as np\n",
    "import zipfile\n",
    "import os\n",
    "import html\n",
    "import re\n",
    "import itertools\n",
    "import lxml\n",
    "import xmltodict\n",
    "import collections\n",
    "from urllib import request\n",
    "from collections import OrderedDict\n",
    "from urllib.error import HTTPError, URLError\n",
    "from urllib.parse import urlparse\n",
    "import sys\n",
    "import ast\n",
    "import time\n",
    "from pandarallel import pandarallel\n",
    "import requests\n",
    "import datefinder\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import psutil\n",
    "from selenium import webdriver\n",
    "from multiprocessing import Pool\n",
    "import random\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "country = \"\"\n",
    "news_outlet = \"\"\n",
    "extract_text_sleep = random.randint(2,4)\n",
    "date_format = \"%Y-%m-%d\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['links_to_be_processed/Wooseong/links_spain_lasprovincias.csv', 'links_to_be_processed/Wooseong/links_spain_abcdesevilla.csv']\n"
     ]
    }
   ],
   "source": [
    "filepaths = ['links_to_be_processed/Wooseong/links_spain_lasprovincias.csv','links_to_be_processed/Wooseong/links_spain_abcdesevilla.csv']\n",
    "# filepaths = []\n",
    "\n",
    "# for path in Path('./links_to_be_processed/Wooseong').rglob('*.csv'):\n",
    "#     if 'unprocessed' not in str(path):\n",
    "#         filepaths.append(str(path))\n",
    "\n",
    "print(filepaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallelize_dataframe(df, func, n_cores):\n",
    "    df_split = np.array_split(df, n_cores)\n",
    "    pool = Pool(n_cores)\n",
    "    df = pd.concat(pool.map(func, df_split))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text(url):\n",
    "    global country, news_outlet\n",
    "    text, title, date = None, None, None\n",
    "    try:\n",
    "        result = [country, news_outlet] + [''] * 3 \n",
    "        article = Article(url, keep_article_html=False)\n",
    "        article.download()\n",
    "        time.sleep(extract_text_sleep)\n",
    "        article.parse()\n",
    "        text = article.text\n",
    "        \n",
    "        if text:\n",
    "            text_copy = text\n",
    "            title = article.title\n",
    "            date = article.publish_date\n",
    "            if date:\n",
    "                date = date.strftime(date_format)\n",
    "            else:\n",
    "                matches = datefinder.find_dates(text_copy)\n",
    "                most_recent_datetime = sorted(matches)[-1]\n",
    "                date = most_recent_datetime.strftime(date_format)\n",
    "    finally:\n",
    "      if title:\n",
    "        result[2] = title\n",
    "      if date:\n",
    "        result[3] = date\n",
    "      if text:\n",
    "        result[4] = text\n",
    "      return result \n",
    "\n",
    "\n",
    "def extract_text_from_df(df):\n",
    "    content = df['link'].map(lambda x: extract_text(x))\n",
    "    df['content'] = content\n",
    "    df[['country', 'news_outlet', 'title', 'date', 'text']] = pd.DataFrame(df.content.tolist(), index= df.index)\n",
    "    df = df.drop(['content'], axis=1)\n",
    "    if 'Unnamed: 0' in df:\n",
    "        df = df.drop(['Unnamed: 0'], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing links file links_to_be_processed/Wooseong/links_spain_lasprovincias.csv\n",
      "159 / 160 text retrieved\n",
      "Total text which has been successfully read till now - 99.38%\n",
      "Batch of data of row range 0-160 complete in 27.79 seconds\n",
      "0.07% complete\n",
      "Processing links file links_to_be_processed/Wooseong/links_spain_lasprovincias.csv\n",
      "160 / 160 text retrieved\n",
      "Total text which has been successfully read till now - 99.69%\n",
      "Batch of data of row range 160-320 complete in 27.48 seconds\n",
      "0.14% complete\n",
      "Processing links file links_to_be_processed/Wooseong/links_spain_lasprovincias.csv\n",
      "159 / 160 text retrieved\n",
      "Total text which has been successfully read till now - 99.58%\n",
      "Batch of data of row range 320-480 complete in 28.5 seconds\n",
      "0.21% complete\n",
      "Processing links file links_to_be_processed/Wooseong/links_spain_lasprovincias.csv\n",
      "160 / 160 text retrieved\n",
      "Total text which has been successfully read till now - 99.69%\n",
      "Batch of data of row range 480-640 complete in 28.07 seconds\n",
      "0.28% complete\n",
      "Processing links file links_to_be_processed/Wooseong/links_spain_lasprovincias.csv\n",
      "160 / 160 text retrieved\n",
      "Total text which has been successfully read till now - 99.75%\n",
      "Batch of data of row range 640-800 complete in 28.5 seconds\n",
      "0.34% complete\n",
      "Processing links file links_to_be_processed/Wooseong/links_spain_lasprovincias.csv\n",
      "160 / 160 text retrieved\n",
      "Total text which has been successfully read till now - 99.79%\n",
      "Batch of data of row range 800-960 complete in 28.08 seconds\n",
      "0.41% complete\n",
      "Processing links file links_to_be_processed/Wooseong/links_spain_lasprovincias.csv\n",
      "159 / 160 text retrieved\n",
      "Total text which has been successfully read till now - 99.73%\n",
      "Batch of data of row range 960-1120 complete in 29.16 seconds\n",
      "0.48% complete\n",
      "Processing links file links_to_be_processed/Wooseong/links_spain_lasprovincias.csv\n",
      "160 / 160 text retrieved\n",
      "Total text which has been successfully read till now - 99.77%\n",
      "Batch of data of row range 1120-1280 complete in 28.89 seconds\n",
      "0.55% complete\n",
      "Processing links file links_to_be_processed/Wooseong/links_spain_lasprovincias.csv\n",
      "159 / 160 text retrieved\n",
      "Total text which has been successfully read till now - 99.72%\n",
      "Batch of data of row range 1280-1440 complete in 27.86 seconds\n",
      "0.62% complete\n",
      "Processing links file links_to_be_processed/Wooseong/links_spain_lasprovincias.csv\n",
      "160 / 160 text retrieved\n",
      "Total text which has been successfully read till now - 99.75%\n",
      "Batch of data of row range 1440-1600 complete in 27.35 seconds\n",
      "0.69% complete\n",
      "Processing links file links_to_be_processed/Wooseong/links_spain_lasprovincias.csv\n",
      "160 / 160 text retrieved\n",
      "Total text which has been successfully read till now - 99.77%\n",
      "Batch of data of row range 1600-1760 complete in 28.08 seconds\n",
      "0.76% complete\n",
      "Processing links file links_to_be_processed/Wooseong/links_spain_lasprovincias.csv\n",
      "159 / 160 text retrieved\n",
      "Total text which has been successfully read till now - 99.74%\n",
      "Batch of data of row range 1760-1920 complete in 27.18 seconds\n",
      "0.83% complete\n",
      "Processing links file links_to_be_processed/Wooseong/links_spain_lasprovincias.csv\n",
      "159 / 160 text retrieved\n",
      "Total text which has been successfully read till now - 99.71%\n",
      "Batch of data of row range 1920-2080 complete in 28.47 seconds\n",
      "0.9% complete\n",
      "Processing links file links_to_be_processed/Wooseong/links_spain_lasprovincias.csv\n",
      "159 / 160 text retrieved\n",
      "Total text which has been successfully read till now - 99.69%\n",
      "Batch of data of row range 2080-2240 complete in 27.47 seconds\n",
      "0.96% complete\n",
      "Processing links file links_to_be_processed/Wooseong/links_spain_lasprovincias.csv\n",
      "159 / 160 text retrieved\n",
      "Total text which has been successfully read till now - 99.67%\n",
      "Batch of data of row range 2240-2400 complete in 28.13 seconds\n",
      "1.03% complete\n",
      "Processing links file links_to_be_processed/Wooseong/links_spain_lasprovincias.csv\n",
      "160 / 160 text retrieved\n",
      "Total text which has been successfully read till now - 99.69%\n",
      "Batch of data of row range 2400-2560 complete in 27.61 seconds\n",
      "1.1% complete\n",
      "Processing links file links_to_be_processed/Wooseong/links_spain_lasprovincias.csv\n",
      "160 / 160 text retrieved\n",
      "Total text which has been successfully read till now - 99.71%\n",
      "Batch of data of row range 2560-2720 complete in 27.92 seconds\n",
      "1.17% complete\n"
     ]
    }
   ],
   "source": [
    "for filepath in filepaths: \n",
    "    root,owner,filename =  filepath.split('/')\n",
    "    filename = filename.replace('links_','')\n",
    "    \n",
    "    country, news_outlet = filename.replace(\".csv\",\"\").split(\"_\")\n",
    "    output_path = root+'/'+owner+'/results'\n",
    "    output_path_file = output_path + '/' + 'unprocessed_' + filename\n",
    "    final_output_file = output_path +  '/' + filename\n",
    "    \n",
    "    if not(os.path.exists(output_path)):\n",
    "        os.mkdir(output_path)\n",
    "        \n",
    "    df = pd.read_csv(filepath)\n",
    "    \n",
    "    start = 0\n",
    "#     if filepath == \"links_to_be_processed/wooseong/links_spain_eldiariovasco.csv\":\n",
    "#         start = 52000\n",
    "#     else:\n",
    "#         start = 0\n",
    "        \n",
    "    limit = 160\n",
    "    number_of_cores = 40\n",
    "    completed = 0\n",
    "    failed_to_retrieve_unprocessed = False\n",
    "    \n",
    "    res = []\n",
    "    while start < len(df):\n",
    "        start_time = time.time()\n",
    "        demo_df = df[start:start+limit].copy()\n",
    "        no_of_text_retrieved = 0\n",
    "        \n",
    "        test_df = parallelize_dataframe(demo_df, extract_text_from_df, number_of_cores)\n",
    "        no_of_text_retrieved = (test_df['text'] != '').sum()\n",
    "        \n",
    "            \n",
    "        test_df.to_csv(output_path_file, mode='a', header=not os.path.exists(output_path_file))\n",
    "        res.append(test_df)\n",
    "       \n",
    "        \n",
    "        if completed == 0 and start != 0:\n",
    "            try:\n",
    "                unprocessed_csv_df = pd.read_csv(output_path_file, converters={'content': pd.eval})\n",
    "                completed = unprocessed_csv_df['content'].map(lambda x: True if x[4] != '' else False).sum()\n",
    "            except:\n",
    "                try:\n",
    "                    unprocessed_csv_df = pd.read_csv(output_path_file, on_bad_lines='skip', converters={'content': pd.eval})\n",
    "                    completed = unprocessed_csv_df['content'].map(lambda x: True if x[4] != '' else False).sum()\n",
    "                except:\n",
    "                    failed_to_retrieve_unprocessed = True\n",
    "            \n",
    "        print(f'Processing links file {filepath}')\n",
    "        print(f'{no_of_text_retrieved} / {len(test_df)} text retrieved')\n",
    "        if not failed_to_retrieve_unprocessed:\n",
    "            completed += no_of_text_retrieved\n",
    "            print(f'Total text which has been successfully read till now - {round((((completed) / (start+limit))* 100), 2)}%')\n",
    "        \n",
    "        end_time = time.time()\n",
    "        \n",
    "        print(f'Batch of data of row range {start}-{start+limit} complete in {round(end_time-start_time, 2)} seconds')\n",
    "        \n",
    "        print(f'{round(min((((start+limit) / len(df)) * 100), 100), 2)}% complete')\n",
    "        start+=limit\n",
    "    \n",
    "    res_df = pd.concat(res)\n",
    "    if not(os.path.exists(final_output_file)):\n",
    "        res_df.to_csv(final_output_file) \n",
    "    else:\n",
    "        print(f\"{final_output_file} already exists. Did not create new csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
