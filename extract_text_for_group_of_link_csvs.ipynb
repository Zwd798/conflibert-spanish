{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import wget\n",
    "import newspaper\n",
    "from newspaper import Article\n",
    "import json\n",
    "import pandas as pd\n",
    "pd.set_option(\"max_colwidth\", 600)\n",
    "import ast\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import requests\n",
    "import time\n",
    "import numpy as np\n",
    "import zipfile\n",
    "import os\n",
    "import html\n",
    "import re\n",
    "import itertools\n",
    "import lxml\n",
    "import xmltodict\n",
    "import collections\n",
    "from urllib import request\n",
    "from collections import OrderedDict\n",
    "from urllib.error import HTTPError, URLError\n",
    "from urllib.parse import urlparse\n",
    "import sys\n",
    "import ast\n",
    "import time\n",
    "from pandarallel import pandarallel\n",
    "import requests\n",
    "import datefinder\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import psutil\n",
    "from selenium import webdriver\n",
    "from multiprocessing import Pool\n",
    "import random\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "country = \"\"\n",
    "news_outlet = \"\"\n",
    "extract_text_sleep = random.randint(2,4)\n",
    "date_format = \"%Y-%m-%d\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['links_to_be_processed/Wooseong/links_spain_lasprovincias.csv', 'links_to_be_processed/Wooseong/links_spain_abcdesevilla.csv']\n"
     ]
    }
   ],
   "source": [
    "filepaths = ['links_to_be_processed/Wooseong/links_spain_lasprovincias.csv','links_to_be_processed/Wooseong/links_spain_abcdesevilla.csv']\n",
    "# filepaths = []\n",
    "\n",
    "# for path in Path('./links_to_be_processed/Wooseong').rglob('*.csv'):\n",
    "#     if 'unprocessed' not in str(path):\n",
    "#         filepaths.append(str(path))\n",
    "\n",
    "print(filepaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallelize_dataframe(df, func, n_cores):\n",
    "    df_split = np.array_split(df, n_cores)\n",
    "    pool = Pool(n_cores)\n",
    "    df = pd.concat(pool.map(func, df_split))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text(url):\n",
    "    global country, news_outlet\n",
    "    text, title, date = None, None, None\n",
    "    try:\n",
    "        result = [country, news_outlet] + [''] * 3 \n",
    "        article = Article(url, keep_article_html=False)\n",
    "        article.download()\n",
    "        time.sleep(extract_text_sleep)\n",
    "        article.parse()\n",
    "        text = article.text\n",
    "        \n",
    "        if text:\n",
    "            text_copy = text\n",
    "            title = article.title\n",
    "            date = article.publish_date\n",
    "            if date:\n",
    "                date = date.strftime(date_format)\n",
    "            else:\n",
    "                matches = datefinder.find_dates(text_copy)\n",
    "                most_recent_datetime = sorted(matches)[-1]\n",
    "                date = most_recent_datetime.strftime(date_format)\n",
    "    finally:\n",
    "      if title:\n",
    "        result[2] = title\n",
    "      if date:\n",
    "        result[3] = date\n",
    "      if text:\n",
    "        result[4] = text\n",
    "      return result \n",
    "\n",
    "\n",
    "def extract_text_from_df(df):\n",
    "    content = df['link'].map(lambda x: extract_text(x))\n",
    "    df['content'] = content\n",
    "    df[['country', 'news_outlet', 'title', 'date', 'text']] = pd.DataFrame(df.content.tolist(), index= df.index)\n",
    "    df = df.drop(['content'], axis=1)\n",
    "    if 'Unnamed: 0' in df:\n",
    "        df = df.drop(['Unnamed: 0'], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-a03576859728>:42: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  unprocessed_csv_df = pd.read_csv(output_path_file, converters={'content': pd.eval})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing links file links_to_be_processed/Wooseong/links_spain_lasprovincias.csv\n",
      "160 / 160 text retrieved\n",
      "Batch of data of row range 192640-192800 complete in 28.96 seconds\n",
      "83.05% complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-a03576859728>:46: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  unprocessed_csv_df = pd.read_csv(output_path_file, on_bad_lines='skip', converters={'content': pd.eval})\n",
      "<ipython-input-6-a03576859728>:42: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  unprocessed_csv_df = pd.read_csv(output_path_file, converters={'content': pd.eval})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing links file links_to_be_processed/Wooseong/links_spain_lasprovincias.csv\n",
      "160 / 160 text retrieved\n",
      "Batch of data of row range 192800-192960 complete in 30.27 seconds\n",
      "83.12% complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-a03576859728>:46: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  unprocessed_csv_df = pd.read_csv(output_path_file, on_bad_lines='skip', converters={'content': pd.eval})\n",
      "<ipython-input-6-a03576859728>:42: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  unprocessed_csv_df = pd.read_csv(output_path_file, converters={'content': pd.eval})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing links file links_to_be_processed/Wooseong/links_spain_lasprovincias.csv\n",
      "160 / 160 text retrieved\n",
      "Batch of data of row range 192960-193120 complete in 30.41 seconds\n",
      "83.19% complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-a03576859728>:46: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  unprocessed_csv_df = pd.read_csv(output_path_file, on_bad_lines='skip', converters={'content': pd.eval})\n",
      "<ipython-input-6-a03576859728>:42: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  unprocessed_csv_df = pd.read_csv(output_path_file, converters={'content': pd.eval})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing links file links_to_be_processed/Wooseong/links_spain_lasprovincias.csv\n",
      "160 / 160 text retrieved\n",
      "Batch of data of row range 193120-193280 complete in 30.81 seconds\n",
      "83.26% complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-a03576859728>:46: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  unprocessed_csv_df = pd.read_csv(output_path_file, on_bad_lines='skip', converters={'content': pd.eval})\n",
      "<ipython-input-6-a03576859728>:42: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  unprocessed_csv_df = pd.read_csv(output_path_file, converters={'content': pd.eval})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing links file links_to_be_processed/Wooseong/links_spain_lasprovincias.csv\n",
      "160 / 160 text retrieved\n",
      "Batch of data of row range 193280-193440 complete in 30.6 seconds\n",
      "83.33% complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-a03576859728>:46: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  unprocessed_csv_df = pd.read_csv(output_path_file, on_bad_lines='skip', converters={'content': pd.eval})\n",
      "<ipython-input-6-a03576859728>:42: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  unprocessed_csv_df = pd.read_csv(output_path_file, converters={'content': pd.eval})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing links file links_to_be_processed/Wooseong/links_spain_lasprovincias.csv\n",
      "160 / 160 text retrieved\n",
      "Batch of data of row range 193440-193600 complete in 35.4 seconds\n",
      "83.4% complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-a03576859728>:46: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  unprocessed_csv_df = pd.read_csv(output_path_file, on_bad_lines='skip', converters={'content': pd.eval})\n",
      "<ipython-input-6-a03576859728>:42: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  unprocessed_csv_df = pd.read_csv(output_path_file, converters={'content': pd.eval})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing links file links_to_be_processed/Wooseong/links_spain_lasprovincias.csv\n",
      "160 / 160 text retrieved\n",
      "Batch of data of row range 193600-193760 complete in 41.55 seconds\n",
      "83.47% complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-a03576859728>:46: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  unprocessed_csv_df = pd.read_csv(output_path_file, on_bad_lines='skip', converters={'content': pd.eval})\n",
      "<ipython-input-6-a03576859728>:42: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  unprocessed_csv_df = pd.read_csv(output_path_file, converters={'content': pd.eval})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing links file links_to_be_processed/Wooseong/links_spain_lasprovincias.csv\n",
      "160 / 160 text retrieved\n",
      "Batch of data of row range 193760-193920 complete in 34.85 seconds\n",
      "83.54% complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-a03576859728>:46: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  unprocessed_csv_df = pd.read_csv(output_path_file, on_bad_lines='skip', converters={'content': pd.eval})\n",
      "<ipython-input-6-a03576859728>:42: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  unprocessed_csv_df = pd.read_csv(output_path_file, converters={'content': pd.eval})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing links file links_to_be_processed/Wooseong/links_spain_lasprovincias.csv\n",
      "160 / 160 text retrieved\n",
      "Batch of data of row range 193920-194080 complete in 39.29 seconds\n",
      "83.6% complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-a03576859728>:46: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  unprocessed_csv_df = pd.read_csv(output_path_file, on_bad_lines='skip', converters={'content': pd.eval})\n",
      "<ipython-input-6-a03576859728>:42: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  unprocessed_csv_df = pd.read_csv(output_path_file, converters={'content': pd.eval})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing links file links_to_be_processed/Wooseong/links_spain_lasprovincias.csv\n",
      "160 / 160 text retrieved\n",
      "Batch of data of row range 194080-194240 complete in 40.56 seconds\n",
      "83.67% complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-a03576859728>:46: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  unprocessed_csv_df = pd.read_csv(output_path_file, on_bad_lines='skip', converters={'content': pd.eval})\n"
     ]
    }
   ],
   "source": [
    "for filepath in filepaths: \n",
    "    root,owner,filename =  filepath.split('/')\n",
    "    filename = filename.replace('links_','')\n",
    "    \n",
    "    country, news_outlet = filename.replace(\".csv\",\"\").split(\"_\")\n",
    "    output_path = root+'/'+owner+'/results'\n",
    "    output_path_file = output_path + '/' + 'unprocessed_' + filename\n",
    "    final_output_file = output_path +  '/' + filename\n",
    "    \n",
    "    if not(os.path.exists(output_path)):\n",
    "        os.mkdir(output_path)\n",
    "        \n",
    "    df = pd.read_csv(filepath)\n",
    "    \n",
    "    start = 0\n",
    "    if filepath == \"links_to_be_processed/Wooseong/links_spain_lasprovincias.csv\":\n",
    "        start = 192640\n",
    "    else:\n",
    "        start = 0\n",
    "        \n",
    "    limit = 160\n",
    "    number_of_cores = 40\n",
    "    completed = 0\n",
    "    failed_to_retrieve_unprocessed = False\n",
    "    \n",
    "    res = []\n",
    "    while start < len(df):\n",
    "        start_time = time.time()\n",
    "        demo_df = df[start:start+limit].copy()\n",
    "        no_of_text_retrieved = 0\n",
    "        \n",
    "        test_df = parallelize_dataframe(demo_df, extract_text_from_df, number_of_cores)\n",
    "        no_of_text_retrieved = (test_df['text'] != '').sum()\n",
    "        \n",
    "            \n",
    "        test_df.to_csv(output_path_file, mode='a', header=not os.path.exists(output_path_file))\n",
    "        res.append(test_df)\n",
    "       \n",
    "        \n",
    "        if completed == 0 and start != 0:\n",
    "            try:\n",
    "                unprocessed_csv_df = pd.read_csv(output_path_file, converters={'content': pd.eval})\n",
    "                completed = unprocessed_csv_df['content'].map(lambda x: True if x[4] != '' else False).sum()\n",
    "            except:\n",
    "                try:\n",
    "                    unprocessed_csv_df = pd.read_csv(output_path_file, on_bad_lines='skip', converters={'content': pd.eval})\n",
    "                    completed = unprocessed_csv_df['content'].map(lambda x: True if x[4] != '' else False).sum()\n",
    "                except:\n",
    "                    failed_to_retrieve_unprocessed = True\n",
    "            \n",
    "        print(f'Processing links file {filepath}')\n",
    "        print(f'{no_of_text_retrieved} / {len(test_df)} text retrieved')\n",
    "        if not failed_to_retrieve_unprocessed:\n",
    "            completed += no_of_text_retrieved\n",
    "            print(f'Total text which has been successfully read till now - {round((((completed) / (start+limit))* 100), 2)}%')\n",
    "        \n",
    "        end_time = time.time()\n",
    "        \n",
    "        print(f'Batch of data of row range {start}-{start+limit} complete in {round(end_time-start_time, 2)} seconds')\n",
    "        \n",
    "        print(f'{round(min((((start+limit) / len(df)) * 100), 100), 2)}% complete')\n",
    "        start+=limit\n",
    "    \n",
    "    res_df = pd.concat(res)\n",
    "    if not(os.path.exists(final_output_file)):\n",
    "        res_df.to_csv(final_output_file) \n",
    "    else:\n",
    "        print(f\"{final_output_file} already exists. Did not create new csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
